<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="">
  <meta name="keywords" content="NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Scaled IG</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>

<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Scaled Inverse Graphics: <br> Efficiently Learning Large Sets of 3D Scenes</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=0dObvuYAAAAJ&hl=fr">Karim Kassab</a><sup>* 1,2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=CcjdVBgAAAAJ&hl=fr">Antoine Schnepf</a><sup>* 1,3</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=IL2OzksAAAAJ&hl=fr">Jean-Yves Franceschi</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=N0YTGr8AAAAJ&hl=en">Laurent Caraffa</a><sup>2</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=L7qb6ToAAAAJ&hl=en">Flavian Vasile</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=T3dQRjAAAAAJ&hl=fr">Jeremie Mary</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=8UW2vacAAAAJ&hl=en">Andrew Comport</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.fr/citations?user=mqq6zX4AAAAJ&hl=en">Valérie Gouet-Brunet</a><sup>2</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>* </sup>equal contributions</span><br>
            <span class="author-block"><sup>1 </sup>Criteo AI Lab, Paris, France</span><br>
            <span class="author-block"><sup>2 </sup>LASTIG, Université Gustave Eiffel, IGN-ENSG, F-94160 Saint-Mandé</span><br>
            <span class="author-block"><sup>3 </sup>Université Côte d’Azur, CNRS, I3S, France</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (coming soon)</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data (coming soon)</span>
                  </a> -->
            </div>
            <video id="large-scale" autoplay muted loop playsinline height="100%">
              <source src="./static/videos/ls_video.mp4"
                      type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
###
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <video id="large-scale" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/ls_video.mp4"
                  type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstracts</h2>
        <div class="content has-text-justified">
          While the field of inverse graphics has been witnessing continuous growth, techniques devised thus far predominantly focus on learning individual scene representations. 
          In contrast, learning large sets of scenes has been a considerable bottleneck in NeRF developments, as repeatedly applying inverse graphics on a sequence of scenes, 
          though essential for various applications, remains largely prohibitive in terms of resource costs. 
          We introduce a framework termed "scaled inverse graphics", aimed at efficiently learning large sets of scene representations, and propose a novel method to this end. 
          It operates in two stages: (i) training a compression model on a subset of scenes, then (ii) training NeRF models on the resulting smaller representations, thereby reducing the optimization space per new scene. 
          In practice, we compact the representation of scenes by learning NeRFs in a latent space to reduce the image resolution, and sharing information across scenes to reduce NeRF representation complexity. 
          We experimentally show that our method presents both the lowest training time and memory footprint in scaled inverse graphics compared to other methods applied independently on each scene. 
          Our codebase is publicly available as open-source.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!-- Method. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <br><br>
        <div class="content has-text-justified">
          <div class="columns is-centered has-text-centered">
            <img src="static/images/learning-many-scenes.svg" alt="Method Scheme" width="75%"/>
          </div>
          <p>
            <b>Learning a large set of scenes.</b> 
            We learn a large set of scenes using a two-stage approach.
            Stage 1 jointly learns a small subset of scenes by training the micro-planes \(\mathcal{T}_1^\mathrm{mic}\), the shared base planes \(\mathcal{B}\), the weights \(W_i\), as well as the encoder \(E_\phi\) and decoder \(D_\psi\).
            Stage 2 learns the rest of the scenes by training \(\mathcal{T}_2^\mathrm{mic}\) and \(W_i\) while fine-tuning \(D_\psi\) and \(\mathcal{B}\).
            This stage exclusively uses \(\mathcal{L}^\mathrm{(latent)}\), and then switches to \(\mathcal{L}^\mathrm{(RGB)}\).
            Note that \(T_i^\mathrm{mac}\) is computed by a weighted summation over the \(M\) shared base planes \(\mathcal{B}\), with weights \(W_i\). 
          </p>
        </div>
        <br/>
      </div>
    </div>
  </div>
</section>
<!--/ Mehtod -->

<!-- BibTex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{sig,
      title     = {{Scaled Inverse Graphics: Efficiently Learning Large Sets of 3D Scenes}},
      author    = {},
      journal   = {},
      year      = {2024}
    }</code></pre>
  </div>
</section>
<!--/ BibTex -->


<!-- Thanks -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website was built on top of the <a href="https://github.com/nerfies/nerfies.github.io">following template</a>, for which we thank the authors.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
<!--/ Thanks -->

</body>
</html>
